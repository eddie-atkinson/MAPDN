{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this notebook is to process the network models from the [CSIRO Low Voltage Feeder Taxonomy](http://linked.data.gov.au/dataset/energy/f325fb3c-2dcd-410c-97a8-e55dc68b8064) project.\n",
    "\n",
    "These network models are specified as Open DSS input files. We need them in Pandapower format in order to work with the MAPDN simulation setup.\n",
    "\n",
    "\n",
    "For this project we will convert the network models of the following networks:\n",
    "- J\n",
    "- Q\n",
    "- L\n",
    "\n",
    "These networks were selected as they were highlighted in the Low Voltage Feeder Taxonomy report as networks with significant voltage challenges. As such, they are good test cases for reinforcement learning agents. \n",
    "## Approach\n",
    "\n",
    "The approach for converting networks will be semi-automatic. The aim will be to write scripts which can convert the line codes, loads and lines into dictionaries than can be loaded into pandapower directly. But, there are some elements of the OpenDSS models that will not translate as easily and will require some manual intervention. \n",
    "\n",
    "Notably, we will be removing transformers from the models. \n",
    "\n",
    "This is done for several reasons. Firstly, the reinforcement learning agents have no control over transformer tap settings (as they have in previous studies), and the metric used to measure agent performance is bus voltages, not reverse power flows across a transformer. Secondly, there are significant data quality issues with the transformer configurations produced by the LVFT as a result of the poor quality input data they received from DNSPs. \"...and inconsistent or missing switch labelling, impedance representations and transformer configurations were among the most problematic and prevalent features of the majority of network models provided\". Finally, the process for converting transformer representations from OpenDSS to Pandapower is not evident. Consequently it was deemed that attempting to convert network elements that were not required for the model, likely misconfigured, and difficult to translate across modelling paradigms would be a net negative for the modelling accuracy of the project.\n",
    "\n",
    "One of the major challenges here will be creating a correspondence between bus numbers given in the OpenDSS files and those in Pandapower. In the OpenDSS files the buses are given arbitrary numbers whilst in Pandapower buses are counted in the order they are created in starting from 0.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Three phase powerflow\n",
    "\n",
    "One of the contributions of this project is to use a 3 phase unbalanced power flow as the basis for the environment agents interact with. For the sake of simplicity we assume that loads are single phase and their PV systems are attached to the same phase.\n",
    "\n",
    "Where the OpenDSS files show that a load is attached to multiple phases, one of the phases is randomly selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "import re\n",
    "import operator\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import pandapower as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for creating test and training sets later\n",
    "# Dates sourced from: https://www.calendardate.com/year2018.php\n",
    "SPRING_START = datetime(2018, 3, 20, 0, 0, 0)\n",
    "SPRING_END = datetime(2018, 6, 20, 0, 0, 0)\n",
    "\n",
    "SUMMER_START = datetime(2018, 6, 21, 0, 0)\n",
    "SUMMER_END = datetime(2018, 9, 21, 0, 0)\n",
    "\n",
    "AUTUMN_START = datetime(2018, 9, 22, 0, 0)\n",
    "AUTUMN_END = datetime(2018, 12, 20, 0, 0)\n",
    "\n",
    "START_OF_YEAR = datetime(2018, 1, 1, 0, 0)\n",
    "WINTER_START = datetime(2018, 12, 21, 0, 0)\n",
    "END_OF_YEAR = datetime(2018, 12, 31, 0, 0)\n",
    "\n",
    "\n",
    "INPUT_DATA_PATH = Path(\"./input_network_models\")\n",
    "OUTPUT_DATA_PATH = Path(\"./output_network_models\")\n",
    "NETWORKS_INFO = {\n",
    "    \"J\": {\n",
    "        \"slack_bus_index\": 21,\n",
    "        \"ext_grid_pu\": 1.04,\n",
    "    },\n",
    "    \"Q\": {\n",
    "        \"slack_bus_index\": 116,\n",
    "        \"ext_grid_pu\": 1.0,\n",
    "    },\n",
    "    \"L\": {\n",
    "        \"slack_bus_index\": 2,\n",
    "        \"ext_grid_pu\": 1.0,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bunch of useful maps and constants for processing the files\n",
    "x_r_map = {\n",
    "    \"r1\": \"r_ohm_per_km\",\n",
    "    \"r0\": \"r0_ohm_per_km\",\n",
    "    \"x1\": \"x_ohm_per_km\",\n",
    "    \"x0\": \"x0_ohm_per_km\",\n",
    "    \"c0\": \"c0_nf_per_km\",\n",
    "    \"c1\": \"c_nf_per_km\",\n",
    "}\n",
    "\n",
    "lines_treatment_map = {\n",
    "    \"length\": {\n",
    "        \"fn\": lambda x: float(x),\n",
    "        \"name\": \"length_km\",\n",
    "    },\n",
    "    \"bus1\": {\n",
    "        \"fn\": lambda x: x.split(\".\")[0],\n",
    "        \"name\": \"from_bus\",\n",
    "    },\n",
    "    \"bus2\": {\n",
    "        \"fn\": lambda x: x.split(\".\")[0],\n",
    "        \"name\": \"to_bus\",\n",
    "    },\n",
    "    \"enabled\": {\n",
    "        \"fn\": lambda x: True if \"y\" in x or \"true\" in x else False,\n",
    "        \"name\": \"in_service\",\n",
    "    },\n",
    "    \"linecode\": {\"fn\": lambda x: x, \"name\": \"std_type\"},\n",
    "}\n",
    "\n",
    "\n",
    "phase_map = {\"1\": \"a\", \"2\": \"b\", \"3\": \"c\"}\n",
    "\n",
    "ops = {\"+\": operator.add, \"-\": operator.sub, \"*\": operator.mul, \"/\": operator.truediv}\n",
    "\n",
    "# It's not pretty, it's hyper-specific\n",
    "# But it works\n",
    "line_split_regex = r\"[\\w\\.]*=*\\(*[\\w\\s\\.*]+\\)*\\s\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual functions for processing the networks\n",
    "\n",
    "\n",
    "def split_row(row: str) -> List[re.Match]:\n",
    "    return re.finditer(line_split_regex, row, re.MULTILINE)\n",
    "\n",
    "\n",
    "def process_load_row(line: str, bus_index_map: dict):\n",
    "    load_info = {}\n",
    "    for match in split_row(line):\n",
    "        match = str(match.group()).strip().lower()\n",
    "        if \"line.\" in match:\n",
    "            load_info[\"name\"] = match.split(\".\")[1]\n",
    "        elif \"bus1\" in match:\n",
    "            bus_info = match.split(\"=\")[1].split(\".\")\n",
    "            load_info[\"bus\"] = bus_index_map[bus_info[0]]\n",
    "            phases = [v for v in bus_info[1:]]\n",
    "            # If the bus has multiple phases randomly select one to assign it to\n",
    "            load_info[\"phase\"] = phase_map[random.choice(phases)]\n",
    "    return load_info\n",
    "\n",
    "\n",
    "def process_linecode_row(line: str):\n",
    "    line_data = {\n",
    "        \"name\": None,\n",
    "        # We assume 0 capacitance in line with other works\n",
    "        \"c_nf_per_km\": 0,\n",
    "        \"c0_nf_per_km\": 0,\n",
    "        \"r_ohm_per_km\": None,\n",
    "        \"r0_ohm_per_km\": None,\n",
    "        \"x_ohm_per_km\": None,\n",
    "        \"x0_ohm_per_km\": None,\n",
    "        # We don't care about maximum thermal current for the line, we aren't looking at faults -> set it unreasonably high\n",
    "        \"max_i_ka\": 5,\n",
    "        \"std_type\": \"line\",\n",
    "    }\n",
    "\n",
    "    for match in split_row(line):\n",
    "        match = str(match.group()).strip().lower()\n",
    "        if \"linecode\" in match:\n",
    "            line_data[\"name\"] = match.split(\".\")[1]\n",
    "        if match.startswith((\"r1\", \"r0\", \"x0\", \"x1\", \"c0\", \"c1\")):\n",
    "            key, value = process_x_r_property(match)\n",
    "            pp_property_name = x_r_map[key]\n",
    "            line_data[pp_property_name] = value\n",
    "    return line_data\n",
    "\n",
    "\n",
    "def get_file_path_from_list(filename: str, file_list: List[Path]) -> Union[Path, None]:\n",
    "    return next(filter(lambda x: filename in str(x).lower(), file_list), None)\n",
    "\n",
    "\n",
    "def process_x_r_property(property):\n",
    "    # This won't work for nested brackets, lord help us if there are any\n",
    "    key, value = property.split(\"=\")\n",
    "    if \"(\" in value:\n",
    "        # Split on as many spaces as there are between operands\n",
    "        num1, num2, op = re.split(r\"\\s+\", value.replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "        value = ops[op](float(num1), float(num2))\n",
    "    else:\n",
    "        value = float(value)\n",
    "    return key, value\n",
    "\n",
    "\n",
    "def process_line_row(line: str):\n",
    "    row_data = {}\n",
    "    for match in split_row(line):\n",
    "        match = str(match.group()).strip().lower()\n",
    "        if \"line.\" in match:\n",
    "            row_data[\"name\"] = match.split(\".\")[1]\n",
    "        if \"=\" in match:\n",
    "            key, value = match.split(\"=\")\n",
    "            treatment = lines_treatment_map.get(key, None)\n",
    "            if not treatment:\n",
    "                continue\n",
    "            row_data[treatment[\"name\"]] = treatment[\"fn\"](value)\n",
    "    return row_data\n",
    "\n",
    "\n",
    "# Note to future readers: this solution is massively overfit\n",
    "# to the structure of the files I am dealing with.\n",
    "# This is in no way an effort to make a general OpenDSS -> pandapower converter\n",
    "def process_linecodes(linecode_path: Path):\n",
    "    linecodes = []\n",
    "    with open(linecode_path, \"r\") as infile:\n",
    "        for row in infile:\n",
    "            linecodes.append(process_linecode_row(row))\n",
    "    return linecodes\n",
    "\n",
    "\n",
    "def process_lines(lines_path):\n",
    "    buses = []\n",
    "    lines = []\n",
    "    bus_index_map = {}\n",
    "    bus_count = 0\n",
    "    with open(lines_path, \"r\") as infile:\n",
    "        for row in infile:\n",
    "            processed_line = process_line_row(row)\n",
    "            from_bus = processed_line[\"from_bus\"]\n",
    "            to_bus = processed_line[\"to_bus\"]\n",
    "            existing_buses = bus_index_map.keys()\n",
    "            if from_bus not in existing_buses:\n",
    "                buses.append({\"name\": from_bus, \"index\": bus_count})\n",
    "                bus_index_map[from_bus] = bus_count\n",
    "                bus_count += 1\n",
    "            if to_bus not in existing_buses:\n",
    "                buses.append({\"name\": to_bus, \"index\": bus_count})\n",
    "                bus_index_map[to_bus] = bus_count\n",
    "                bus_count += 1\n",
    "            lines.append(\n",
    "                {\n",
    "                    **processed_line,\n",
    "                    \"from_bus\": bus_index_map[from_bus],\n",
    "                    \"to_bus\": bus_index_map[to_bus],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return buses, lines, bus_index_map\n",
    "\n",
    "\n",
    "def process_loads(loads_path, bus_index_map: dict):\n",
    "    loads = []\n",
    "    with open(loads_path, \"r\") as infile:\n",
    "        for row in infile:\n",
    "            loads.append(process_load_row(row, bus_index_map))\n",
    "    return loads\n",
    "\n",
    "\n",
    "def save_json_data(data: dict, file_path: str):\n",
    "    with open(file_path, \"w\") as outfile:\n",
    "        outfile.write(json.dumps(data))\n",
    "\n",
    "\n",
    "def load_json(file_path: Path) -> dict:\n",
    "    with open(file_path, \"r\") as infile:\n",
    "        return json.loads(infile.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "\n",
    "def process_network(network_name: str):\n",
    "    input_network_path = INPUT_DATA_PATH / network_name\n",
    "    output_network_path = OUTPUT_DATA_PATH / network_name\n",
    "\n",
    "    file_list = list(input_network_path.iterdir())\n",
    "\n",
    "    linecodes_path = get_file_path_from_list(\"linecode\", file_list)\n",
    "    lines_path = get_file_path_from_list(\"lines\", file_list)\n",
    "    loads_path = get_file_path_from_list(\"loads\", file_list)\n",
    "\n",
    "    if any(x is None for x in [linecodes_path, lines_path, loads_path]):\n",
    "        raise ValueError(f\"Can't process network without linecodes, lines and loads\")\n",
    "    linecodes = process_linecodes(linecodes_path)\n",
    "    buses, lines, bus_index_map = process_lines(lines_path)\n",
    "    loads = process_loads(loads_path, bus_index_map)\n",
    "\n",
    "    output_network_path.mkdir(exist_ok=True, parents=True)\n",
    "    save_json_data(linecodes, output_network_path / \"linecodes.json\")\n",
    "    save_json_data(buses, output_network_path / \"buses.json\")\n",
    "    save_json_data(lines, output_network_path / \"lines.json\")\n",
    "    save_json_data(loads, output_network_path / \"loads.json\")\n",
    "\n",
    "    pd.DataFrame(bus_index_map, index=[0]).to_csv(\n",
    "        output_network_path / \"bus_index_map.csv\"\n",
    "    )\n",
    "\n",
    "\n",
    "def build_network(\n",
    "    slack_bus_index,\n",
    "    ext_grid_pu,\n",
    "    path,\n",
    "    base_bus_kv=0.416,\n",
    "    default_load_mw=0,\n",
    "    default_load_mvar=0,\n",
    "    default_sgen_mw=0,\n",
    "    default_sgen_mvar=0,\n",
    "    sgen_proportion=0.5,\n",
    "    random_state=42,\n",
    "):\n",
    "    random.seed(random_state)\n",
    "    bus_path = path / \"buses.json\"\n",
    "    linecodes_path = path / \"linecodes.json\"\n",
    "    lines_path = path / \"lines.json\"\n",
    "    loads_path = path / \"loads.json\"\n",
    "\n",
    "    buses = load_json(bus_path)\n",
    "    loads = load_json(loads_path)\n",
    "    linecodes = load_json(linecodes_path)\n",
    "    lines = load_json(lines_path)\n",
    "\n",
    "    net = pp.create_empty_network()\n",
    "\n",
    "    for linecode in linecodes:\n",
    "        pp.create_std_type(net, linecode, linecode[\"name\"], element=\"line\")\n",
    "\n",
    "    for bus in buses:\n",
    "        pp.create_bus(net, vn_kv=base_bus_kv, **bus)\n",
    "\n",
    "    for line in lines:\n",
    "        pp.create_line(net, **line)\n",
    "\n",
    "    for load in loads:\n",
    "        phase = load[\"phase\"]\n",
    "        bus = load[\"bus\"]\n",
    "        load_data = {\n",
    "            \"net\": net,\n",
    "            \"bus\": bus,\n",
    "            \"name\": phase,\n",
    "            \"p_a_mw\": 0,\n",
    "            \"p_b_mw\": 0,\n",
    "            \"p_c_mw\": 0,\n",
    "            \"q_a_mvar\": 0,\n",
    "            \"q_b_mvar\": 0,\n",
    "            \"q_c_mvar\": 0,\n",
    "            # Override the active and reactive power values set above for the relevant phase\n",
    "            f\"p_{phase}_mw\": default_load_mw,\n",
    "            f\"q_{phase}_mvar\": default_load_mvar,\n",
    "        }\n",
    "        load = pp.create_asymmetric_load(\n",
    "            **load_data,\n",
    "        )\n",
    "\n",
    "        if random.random() <= sgen_proportion:\n",
    "            sgen_data = {\n",
    "                \"net\": net,\n",
    "                \"bus\": bus,\n",
    "                \"name\": phase,\n",
    "                \"p_a_mw\": 0,\n",
    "                \"p_b_mw\": 0,\n",
    "                \"q_a_mvar\": 0,\n",
    "                \"q_b_mvar\": 0,\n",
    "                \"q_c_mvar\": 0,\n",
    "                # Override the active and reactive power values set above for the relevant phase\n",
    "                f\"p_{phase}_mw\": default_sgen_mw,\n",
    "                f\"q_{phase}_mvar\": default_sgen_mvar,\n",
    "            }\n",
    "            pp.create_asymmetric_sgen(**sgen_data)\n",
    "\n",
    "    pp.create_ext_grid(net, slack_bus_index, ext_grid_pu)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "for network, network_info in NETWORKS_INFO.items():\n",
    "    process_network(network)\n",
    "    path = OUTPUT_DATA_PATH / network\n",
    "    net = build_network(**network_info, path=path, sgen_proportion=0.5)\n",
    "    pp.add_zero_impedance_parameters(net)\n",
    "    # Test the network compiles\n",
    "    pp.runpp_3ph(net)\n",
    "    pp.to_pickle(net, str(path / \"model.p\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cool, we have converted some networks and tested they work statically\n",
    "\n",
    "Now let's see what results they produce when we combine them with the real load profiles we have for our main experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATION_RESULTS_PATH = Path(\"./simulation_results\")\n",
    "LOAD_DATA_PATH = Path(\"./output_data\")\n",
    "N_SITES = 109\n",
    "\n",
    "dtypes = {str(i): float for i in range(N_SITES)}\n",
    "\n",
    "reactive_df = pd.read_csv(\n",
    "    LOAD_DATA_PATH / \"test_reactive.csv\", dtype=dtypes, parse_dates=[\"datetime\"]\n",
    ")\n",
    "active_df = pd.read_csv(\n",
    "    LOAD_DATA_PATH / \"test_active.csv\", dtype=dtypes, parse_dates=[\"datetime\"]\n",
    ")\n",
    "solar_df = pd.read_csv(\n",
    "    LOAD_DATA_PATH / \"test_pv.csv\", dtype=dtypes, parse_dates=[\"datetime\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK = \"J\"\n",
    "p = Path(f\"./simulation_results/{NETWORK}/res_bus_3ph\")\n",
    "bus_a_df = pd.read_csv(p / \"vm_a_pu.csv\", index_col=[0])\n",
    "bus_b_df = pd.read_csv(p / \"vm_b_pu.csv\", index_col=[0])\n",
    "bus_c_df = pd.read_csv(p / \"vm_c_pu.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_data(df, phase):\n",
    "    df[\"datetime\"] = solar_df.loc[df.index, \"datetime\"]\n",
    "    df = df.set_index(\"datetime\")\n",
    "    \n",
    "    # Find the dates within the data which pertain to each season\n",
    "    spring_dates = df.loc[(df.index >= SPRING_START) & (df.index <= SPRING_END)].index\n",
    "    autumn_dates = df.loc[(df.index >= AUTUMN_START) & (df.index <= WINTER_START)].index\n",
    "    summer_dates = df.loc[(df.index >= SUMMER_START) & (df.index <= SUMMER_END)].index\n",
    "    winter_dates = df.loc[((df.index >= START_OF_YEAR) & (df.index < SPRING_START)) | ((df.index >= WINTER_START) & (df.index <= END_OF_YEAR))].index\n",
    "    seasons = pd.Series(index=df.index, dtype=\"category\", name=\"season\")\n",
    "    seasons = seasons.cat.set_categories([\"summer\", \"spring\", \"autumn\", \"winter\"])\n",
    "    \n",
    "    # Melt columns to rows\n",
    "    df = df.melt(value_vars=df.columns, ignore_index=False)\n",
    "    \n",
    "    # Add back season and phase info\n",
    "    seasons.loc[spring_dates] = \"spring\"\n",
    "    seasons.loc[summer_dates] = \"summer\"\n",
    "    seasons.loc[autumn_dates] = \"autumn\"\n",
    "    seasons.loc[winter_dates] = \"winter\"\n",
    "    \n",
    "    df[\"phase\"] = phase\n",
    "    df = df.join(seasons)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>phase</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-06 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.009041</td>\n",
       "      <td>a</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.005886</td>\n",
       "      <td>c</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1.005310</td>\n",
       "      <td>c</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06 00:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>1.006269</td>\n",
       "      <td>c</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06 00:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1.005924</td>\n",
       "      <td>c</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-22 23:59:30</th>\n",
       "      <td>4</td>\n",
       "      <td>1.029173</td>\n",
       "      <td>b</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-22 23:59:30</th>\n",
       "      <td>3</td>\n",
       "      <td>1.028394</td>\n",
       "      <td>b</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-22 23:59:30</th>\n",
       "      <td>2</td>\n",
       "      <td>1.028365</td>\n",
       "      <td>b</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-22 23:59:30</th>\n",
       "      <td>15</td>\n",
       "      <td>1.035924</td>\n",
       "      <td>b</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-22 23:59:30</th>\n",
       "      <td>30</td>\n",
       "      <td>1.038426</td>\n",
       "      <td>c</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999040 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     variable     value phase  season\n",
       "datetime                                             \n",
       "2018-01-06 00:00:00         0  1.009041     a  winter\n",
       "2018-01-06 00:00:00         0  1.005886     c  winter\n",
       "2018-01-06 00:00:00         1  1.005310     c  winter\n",
       "2018-01-06 00:00:00         2  1.006269     c  winter\n",
       "2018-01-06 00:00:00         3  1.005924     c  winter\n",
       "...                       ...       ...   ...     ...\n",
       "2018-12-22 23:59:30         4  1.029173     b  winter\n",
       "2018-12-22 23:59:30         3  1.028394     b  winter\n",
       "2018-12-22 23:59:30         2  1.028365     b  winter\n",
       "2018-12-22 23:59:30        15  1.035924     b  winter\n",
       "2018-12-22 23:59:30        30  1.038426     c  winter\n",
       "\n",
       "[14999040 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_a_df = transpose_data(bus_a_df, \"a\")\n",
    "bus_b_df = transpose_data(bus_b_df, \"b\")\n",
    "bus_c_df = transpose_data(bus_c_df, \"c\")\n",
    "\n",
    "bus_df = pd.concat([bus_a_df, bus_b_df, bus_c_df])\n",
    "bus_df[\"variable\"] = bus_df[\"variable\"].astype(int)\n",
    "\n",
    "bus_df = bus_df.sort_index()\n",
    "bus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(bus_df, x=\"variable\", y=\"value\", color=\"phase\", facet_row=\"season\", width=1400, height=500,  category_orders={\"phase\": [\"a\", \"b\", \"c\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4a8b33f54e91e0fba0aee32d2cc6e29e6a619bb4eba0837462f8fb01455034b"
  },
  "kernelspec": {
   "display_name": "mapdn:Python",
   "language": "python",
   "name": "conda-env-mapdn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
